# SQL Data Warehouse Project ğŸ“ˆ

Ce projet prÃ©sente une solution complÃ¨te d'entreposage et d'analyse de donnÃ©es, de la crÃ©ation d'un entrepÃ´t de donnÃ©es Ã  la gÃ©nÃ©ration d'informations exploitables. ConÃ§u comme un projet de portfolio, il met en lumiÃ¨re les meilleures pratiques du secteur en matiÃ¨re d'ingÃ©nierie et d'analyse des donnÃ©es.

## ğŸ—ï¸ Data Architecture

L'architecture de donnÃ©es de ce projet suit le modÃ¨le Medallion Architecture, articulÃ© autour des couches **Bronze**, **Silver** et **Gold**Â :


1. **Couche Bronze**Â : Stocke les donnÃ©es brutes issues des systÃ¨mes sources. Les donnÃ©es sont importÃ©es depuis des fichiers CSV dans une base de donnÃ©es SQL Server.

2. **Couche Silver**Â : Cette couche inclut les processus de nettoyage, de standardisation et de normalisation des donnÃ©es afin de les prÃ©parer Ã  l'analyse.

3. **Couche Gold**Â : Contient les donnÃ©es exploitables par l'entreprise, modÃ©lisÃ©es selon un schÃ©ma en Ã©toile, nÃ©cessaires Ã  la crÃ©ation de rapports et Ã  l'analyse.


## ğŸ“– AperÃ§u du projet

1. **Architecture des donnÃ©es**Â : Conception d'un entrepÃ´t de donnÃ©es moderne Ã  l'aide de l'architecture Medallion (couches Bronze, Silver et Gold).

2. **Pipelines ETL**Â : Extraction, transformation et chargement des donnÃ©es des systÃ¨mes sources vers l'entrepÃ´t.

3. **ModÃ©lisation des donnÃ©es**Â : DÃ©veloppement de tables de faits et de dimensions optimisÃ©es pour les requÃªtes analytiques.

4. **Analyse et reporting**Â : CrÃ©ation de rapports et de tableaux de bord SQL pour des informations exploitables.

## ğŸ“‚ Structure du dÃ©pÃ´t
```
data-warehouse-project/
â”‚
â”œâ”€â”€ datasets/                           # DonnÃ©es brutes utilisÃ©es pour le projet (donnÃ©es ERP et CRM)
â”‚
â”œâ”€â”€ docs/                               # Documentation du projet et dÃ©tails d'architecture
â”‚   â”œâ”€â”€ data_catalog.md                 # Catalogue des jeux de donnÃ©es, comprenant les descriptions des champs et les mÃ©tadonnÃ©es
â”‚   â”œâ”€â”€ data_flow.jpg                   # fichier pour le diagramme de flux de donnÃ©es
â”‚   â”œâ”€â”€ data_models.jpg                 # fichier pour les modÃ¨les de donnÃ©es (schÃ©ma en Ã©toile)
â”‚   â”œâ”€â”€ data_integration                # fichier pour l'intÃ©gration des donnÃ©es
â”‚
â”œâ”€â”€ scripts/                            # Scripts SQL pour l'ETL et les transformations
â”‚   â”œâ”€â”€ bronze/                         # Scripts d'extraction et de chargement de donnÃ©es brutes
â”‚   â”œâ”€â”€ silver/                         # Scripts pour le nettoyage et la transformation des donnÃ©es
â”‚   â”œâ”€â”€ gold/                           # Scripts pour la crÃ©ation de modÃ¨les analytiques
â”‚
â”œâ”€â”€ tests/                              # Scripts de test et fichiers de qualitÃ©
â”‚
â”œâ”€â”€ README.md                           # PrÃ©sentation et instructions du projet
â””â”€â”€ LICENSE                             # Informations de licence pour le dÃ©pÃ´t

## ğŸŒŸ Ã€ propos de moi

Ã‰tudiant en master Big Data & Data Science, je me forme activement au data engineering (Azure, Databricks, Spark, pipelines).
Ancien entrepreneur, je combine rigueur technique et mentalitÃ© orientÃ©e rÃ©sultat.
Je suis Ã  la recherche dâ€™opportunitÃ©s pour appliquer mes compÃ©tences et continuer Ã  progresser.
